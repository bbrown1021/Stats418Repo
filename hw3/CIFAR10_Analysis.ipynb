{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3\n",
    "\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "from skimage import data\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, NMF\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### 1) Load the CIFAR-10 dataset from (https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). (Don’t upload the dataset to github.)\n",
    "\n",
    "To avoid uploading the data to GitHub, the directory with all subsequent data files has been added to the .gitignore for my repo. \n",
    "\n",
    "The CIFAR-10 dataset, according to the README for this dataset (https://www.cs.toronto.edu/~kriz/cifar.html), consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images *which is approximately the 80-20 split requested for this assignment.* \n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10,000 images. The test batch contains exactly 1,000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "The png files can be found here: https://www.kaggle.com/swaroopkml/cifar10-pngs-in-folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open pickled python files\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Data\n",
    "\n",
    "There are 10,000 cases per batch and 3072 values per visual.  \n",
    "There are 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'num_cases_per_batch', b'label_names', b'num_vis'])\n",
      "{b'num_cases_per_batch': 10000, b'label_names': [b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck'], b'num_vis': 3072}\n"
     ]
    }
   ],
   "source": [
    "batches_meta = unpickle(\"data/cifar_10_batches_py/batches.meta\")\n",
    "print(batches_meta.keys())\n",
    "print(batches_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Batch 1\n",
    "\n",
    "There are four keys in each batch: \n",
    "- the batch label\n",
    "- the labels corresponding to the image\n",
    "- the 3072 array to define each image\n",
    "- the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n"
     ]
    }
   ],
   "source": [
    "batch_1 = unpickle(\"data/cifar_10_batches_py/data_batch_1\")\n",
    "print(len(batch_1))\n",
    "print(batch_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(batch_1[b'batch_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(batch_1[b'labels'][:20]) # first 20 image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(batch_1[b'data'][0]) # first image array\n",
    "print(\"Dimension:\", batch_1[b'data'][0].ndim)\n",
    "print(\"Shape:\", batch_1[b'data'][0].shape)\n",
    "print(\"Filename:\", batch_1[b'filenames'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the training set's first image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = list(batch_1.values())[2][0] # extract first set of 3072 values\n",
    "\n",
    "# divide array into 2D arrays for each color\n",
    "# divide by 255 because max value for RGB scale\n",
    "reds = np.reshape(image1[:1024],(32,32))/255\n",
    "greens = np.reshape(image1[1024:2048],(32,32))/255\n",
    "blues = np.reshape(image1[2048:],(32,32))/255\n",
    "\n",
    "# create a 3D array\n",
    "image1 = np.dstack((reds,greens,blues))\n",
    "print(\"Dimension:\", image1.ndim)\n",
    "print(\"Shape:\", image1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.subplot(131)\n",
    "plt.gca().set_title('Red channel')\n",
    "plt.imshow(reds, cmap='Reds', interpolation='nearest')\n",
    "plt.subplot(132)\n",
    "plt.gca().set_title('Green channel')\n",
    "plt.imshow(greens, cmap='Greens', interpolation='nearest')\n",
    "plt.subplot(133)\n",
    "plt.gca().set_title('Blue channel')\n",
    "plt.imshow(blues, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5,2.5))\n",
    "plt.imshow(image1, cmap=plt.cm.gray) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! After converting the arrayThis is an image of a frog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above work helped me understand how the dataset was originally stored. At this point in my analysis, I noticed that the CIFAR-10 dataset could be accessed through Keras.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\tMake an 80%-20% split on the dataset into test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training and testing data is approximately in a 80-20 split.\n",
    "print('Traning data shape:', x_train.shape)\n",
    "print('Testing data shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corresponding training and testing labels\n",
    "print('Traning labels shape:', y_train.shape)\n",
    "print('Testing labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# unique numbers from the train labels\n",
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of classes : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "# from meta data above we know which numbers correspond to which image class\n",
    "label_dict = {\n",
    " 0: 'airplane',\n",
    " 1: 'automobile',\n",
    " 2: 'bird',\n",
    " 3: 'cat',\n",
    " 4: 'deer',\n",
    " 5: 'dog',\n",
    " 6: 'frog',\n",
    " 7: 'horse',\n",
    " 8: 'ship',\n",
    " 9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View example images from training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data (SAME AS ABOVE)\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(x_train[0], (32,32,3))\n",
    "plt.imshow(curr_img)\n",
    "plt.title(str(label_dict[y_train[0][0]]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(x_test[0],(32,32,3))\n",
    "plt.imshow(curr_img)\n",
    "plt.title(str(label_dict[y_test[0][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)\tScale the data so that each feature has a minimum value of 0 and a maximum value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train),np.max(x_train) # current minimum and maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Minimum: 0.0 New Maximum: 1.0\n",
      "Same Training Shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train/255.0\n",
    "print(\"New Minimum:\" , np.min(x_train), \"New Maximum:\" , np.max(x_train))\n",
    "print(\"Same Training Shape:\" ,x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\tUse the following dimensionality reduction techniques for feature extraction: (More in Question 3)\n",
    "    a) Principal Component Analysis\n",
    "    b) Singular Value Decomposition\n",
    "    c) Non-negative Matrix Factorization\n",
    "    \n",
    "To begin, I will create a dataframe of pixel values for each image with their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (50000, 3073)\n"
     ]
    }
   ],
   "source": [
    "# reshape image dimensions from three to one\n",
    "x_train_flat = x_train.reshape(-1,3072)\n",
    "\n",
    "# name each column by pixel number\n",
    "feat_cols = ['p'+str(i + 1) for i in range(x_train_flat.shape[1])]\n",
    "df_cifar = pd.DataFrame(x_train_flat,columns=feat_cols)\n",
    "\n",
    "# add image labels\n",
    "df_cifar['label'] = y_train\n",
    "\n",
    "# check dataframe shape\n",
    "print('Size of the dataframe: {}'.format(df_cifar.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>...</th>\n",
       "      <th>p3064</th>\n",
       "      <th>p3065</th>\n",
       "      <th>p3066</th>\n",
       "      <th>p3067</th>\n",
       "      <th>p3068</th>\n",
       "      <th>p3069</th>\n",
       "      <th>p3070</th>\n",
       "      <th>p3071</th>\n",
       "      <th>p3072</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1        p2        p3        p4        p5        p6        p7  \\\n",
       "0  0.231373  0.243137  0.247059  0.168627  0.180392  0.176471  0.196078   \n",
       "1  0.603922  0.694118  0.733333  0.494118  0.537255  0.533333  0.411765   \n",
       "2  1.000000  1.000000  1.000000  0.992157  0.992157  0.992157  0.992157   \n",
       "3  0.109804  0.098039  0.039216  0.145098  0.133333  0.074510  0.149020   \n",
       "4  0.666667  0.705882  0.776471  0.658824  0.698039  0.768627  0.694118   \n",
       "\n",
       "         p8        p9       p10  ...     p3064     p3065     p3066     p3067  \\\n",
       "0  0.188235  0.168627  0.266667  ...  0.847059  0.721569  0.549020  0.592157   \n",
       "1  0.407843  0.372549  0.400000  ...  0.560784  0.521569  0.545098  0.560784   \n",
       "2  0.992157  0.992157  0.992157  ...  0.305882  0.333333  0.325490  0.309804   \n",
       "3  0.137255  0.078431  0.164706  ...  0.211765  0.184314  0.109804  0.247059   \n",
       "4  0.725490  0.796078  0.717647  ...  0.294118  0.309804  0.321569  0.278431   \n",
       "\n",
       "      p3068     p3069     p3070     p3071     p3072  label  \n",
       "0  0.462745  0.329412  0.482353  0.360784  0.282353      6  \n",
       "1  0.525490  0.556863  0.560784  0.521569  0.564706      9  \n",
       "2  0.333333  0.325490  0.313725  0.337255  0.329412      9  \n",
       "3  0.219608  0.145098  0.282353  0.254902  0.180392      4  \n",
       "4  0.294118  0.305882  0.286275  0.301961  0.313725      1  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cifar.head() # each row is image, each column contains pixel or label info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Principal Component Analysis\n",
    "\n",
    "Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.9) # want PCA model to capture 90% of variance\n",
    "\n",
    "pca.fit(x_train_flat)\n",
    "pca.n_components_ # need 99 components to acheive 90% variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, to achieve 90% variance explained, use 99 principal components compared to the original 3072 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC91</th>\n",
       "      <th>PC92</th>\n",
       "      <th>PC93</th>\n",
       "      <th>PC94</th>\n",
       "      <th>PC95</th>\n",
       "      <th>PC96</th>\n",
       "      <th>PC97</th>\n",
       "      <th>PC98</th>\n",
       "      <th>PC99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.401018</td>\n",
       "      <td>2.729039</td>\n",
       "      <td>1.501711</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-4.452582</td>\n",
       "      <td>0.647150</td>\n",
       "      <td>0.568989</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>3.451771</td>\n",
       "      <td>1.168442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418062</td>\n",
       "      <td>0.226053</td>\n",
       "      <td>-0.056544</td>\n",
       "      <td>-0.318404</td>\n",
       "      <td>-0.716454</td>\n",
       "      <td>-0.523308</td>\n",
       "      <td>-0.447695</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>-0.106993</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829783</td>\n",
       "      <td>-0.949943</td>\n",
       "      <td>6.003753</td>\n",
       "      <td>1.504931</td>\n",
       "      <td>-1.368500</td>\n",
       "      <td>1.225687</td>\n",
       "      <td>0.606882</td>\n",
       "      <td>-0.523086</td>\n",
       "      <td>2.584150</td>\n",
       "      <td>2.565564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460990</td>\n",
       "      <td>-0.114007</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>-0.110551</td>\n",
       "      <td>0.398520</td>\n",
       "      <td>-0.368037</td>\n",
       "      <td>0.374922</td>\n",
       "      <td>-0.281805</td>\n",
       "      <td>-0.379971</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.730200</td>\n",
       "      <td>-11.522102</td>\n",
       "      <td>-2.753621</td>\n",
       "      <td>2.333595</td>\n",
       "      <td>-1.584409</td>\n",
       "      <td>-2.272213</td>\n",
       "      <td>-0.610438</td>\n",
       "      <td>-1.361358</td>\n",
       "      <td>-0.730908</td>\n",
       "      <td>-1.125914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268505</td>\n",
       "      <td>-0.048260</td>\n",
       "      <td>-0.569063</td>\n",
       "      <td>0.183344</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.694297</td>\n",
       "      <td>-0.521619</td>\n",
       "      <td>-0.416999</td>\n",
       "      <td>0.047737</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.347817</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>1.101019</td>\n",
       "      <td>-1.304540</td>\n",
       "      <td>-1.594870</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.232392</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>-0.359152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.146062</td>\n",
       "      <td>-0.197351</td>\n",
       "      <td>0.153781</td>\n",
       "      <td>0.246829</td>\n",
       "      <td>-0.230318</td>\n",
       "      <td>0.161916</td>\n",
       "      <td>0.065638</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.625651</td>\n",
       "      <td>-4.969240</td>\n",
       "      <td>1.034585</td>\n",
       "      <td>3.306459</td>\n",
       "      <td>1.261683</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>5.655493</td>\n",
       "      <td>1.426761</td>\n",
       "      <td>3.918136</td>\n",
       "      <td>-1.955221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679009</td>\n",
       "      <td>0.488839</td>\n",
       "      <td>-0.692370</td>\n",
       "      <td>-0.018541</td>\n",
       "      <td>-0.035966</td>\n",
       "      <td>-0.315796</td>\n",
       "      <td>0.410882</td>\n",
       "      <td>0.145903</td>\n",
       "      <td>0.355507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1        PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  -6.401018   2.729039  1.501711 -2.953333 -4.452582  0.647150  0.568989   \n",
       "1   0.829783  -0.949943  6.003753  1.504931 -1.368500  1.225687  0.606882   \n",
       "2   7.730200 -11.522102 -2.753621  2.333595 -1.584409 -2.272213 -0.610438   \n",
       "3 -10.347817   0.010738  1.101019 -1.304540 -1.594870  0.867600  0.194107   \n",
       "4  -2.625651  -4.969240  1.034585  3.306459  1.261683  0.031241  5.655493   \n",
       "\n",
       "        PC8       PC9      PC10  ...      PC91      PC92      PC93      PC94  \\\n",
       "0  0.092877  3.451771  1.168442  ...  0.418062  0.226053 -0.056544 -0.318404   \n",
       "1 -0.523086  2.584150  2.565564  ... -0.460990 -0.114007  0.031109 -0.110551   \n",
       "2 -1.361358 -0.730908 -1.125914  ...  0.268505 -0.048260 -0.569063  0.183344   \n",
       "3  0.232392  1.467262 -0.359152  ...  0.022401  0.093721  0.146062 -0.197351   \n",
       "4  1.426761  3.918136 -1.955221  ...  0.679009  0.488839 -0.692370 -0.018541   \n",
       "\n",
       "       PC95      PC96      PC97      PC98      PC99  y  \n",
       "0 -0.716454 -0.523308 -0.447695  0.133987 -0.106993  6  \n",
       "1  0.398520 -0.368037  0.374922 -0.281805 -0.379971  9  \n",
       "2  0.333791  0.694297 -0.521619 -0.416999  0.047737  9  \n",
       "3  0.153781  0.246829 -0.230318  0.161916  0.065638  4  \n",
       "4 -0.035966 -0.315796  0.410882  0.145903  0.355507  1  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncomp = 99\n",
    "pca_cifar = PCA(n_components=ncomp)\n",
    "principalComponents_cifar = pca_cifar.fit_transform(df_cifar.iloc[:,:-1])\n",
    "\n",
    "# convert PC into dataframe\n",
    "feat_cols = ['PC'+str(i + 1) for i in range(principalComponents_cifar.shape[1])]\n",
    "principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar, columns = feat_cols)\n",
    "principal_cifar_Df['y'] = y_train\n",
    "principal_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2907663  0.11253144 0.06694414 0.03676459 0.03608843 0.0280923\n",
      " 0.02712992 0.02167162 0.02064641 0.01438001 0.01310563 0.01065978\n",
      " 0.01049981 0.01004269 0.00918482 0.008174   0.00739608 0.0071613\n",
      " 0.00687472 0.00643243 0.00594396 0.00587355 0.00495567 0.00490792\n",
      " 0.00480452 0.00465877 0.00451348 0.00443654 0.00400781 0.00393866\n",
      " 0.00366217 0.0033314  0.00323965 0.00310246 0.00307587 0.0029125\n",
      " 0.00261219 0.00259261 0.00254345 0.00248378 0.00242671 0.0022932\n",
      " 0.00228175 0.00221518 0.0021026  0.00206732 0.00192457 0.00190379\n",
      " 0.0018466  0.00181696 0.00178052 0.001736   0.00171165 0.00169759\n",
      " 0.00162334 0.0015859  0.00156412 0.001543   0.00153092 0.00149923\n",
      " 0.00145783 0.00142325 0.00141115 0.00137706 0.00134853 0.00132664\n",
      " 0.00128842 0.00124309 0.00121383 0.00121199 0.00118513 0.00116823\n",
      " 0.00113991 0.00112302 0.00111627 0.0011102  0.00110244 0.00104774\n",
      " 0.00103586 0.00101727 0.00099838 0.00098963 0.00097765 0.00097181\n",
      " 0.00094219 0.00092738 0.00091825 0.00089843 0.0008827  0.00087738\n",
      " 0.00086375 0.00084109 0.00083765 0.00081585 0.0007998  0.00078838\n",
      " 0.00077854 0.00074423 0.00073818]\n",
      "Total Variance Explained 0.900233498052615\n"
     ]
    }
   ],
   "source": [
    "print(pca_cifar.explained_variance_ratio_)\n",
    "print('Total Variance Explained',sum(pca_cifar.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Singular Value Decomposition\n",
    "\n",
    "In linear algebra, the singular value decomposition is a factorization of a real or complex matrix. It generalizes the eigendecomposition of a square normal matrix with an orthonormal eigenbasis to any m\\times n matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need 95 components to acheive at least 90% variance explained\n",
    "svd = TruncatedSVD(n_components=95)\n",
    "\n",
    "svd.fit(df_cifar)\n",
    "print('Total Variance Explained',svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SVD transform to dataset\n",
    "transformed_svd = svd.fit_transform(df_cifar)\n",
    "transformed_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert SVD into dataframe\n",
    "feat_cols = ['SVD'+str(i + 1) for i in range(transformed_svd.shape[1])]\n",
    "svd_cifar_Df = pd.DataFrame(data = transformed, columns = feat_cols)\n",
    "svd_cifar_Df['y'] = y_train\n",
    "svd_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Non-negative Matrix Factorization\n",
    "\n",
    "Non-negative matrix factorization, also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into two matrices W and H, with the property that all three matrices have no negative elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=100) # arbitrarily choose 100 components\n",
    "trans_nmf = nmf.fit_transform(df_cifar)\n",
    "print(\"Shape:\", trans_nmf.shape)\n",
    "feat_cols = ['NMF'+str(i + 1) for i in range(trans_nmf.shape[1])]\n",
    "nmf_cifar_Df = pd.DataFrame(data = trans_nmf, columns = feat_cols)\n",
    "nmf_cifar_Df['y'] = y_train\n",
    "nmf_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\tBonus: Provide some visualization on how these methods are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp = 2\n",
    "\n",
    "# PCA Example\n",
    "pca_cifar_ex = PCA(n_components=ncomp)\n",
    "principalComponents_cifar_ex = pca_cifar_ex.fit_transform(df_cifar.iloc[:,:-1])\n",
    "\n",
    "principal_cifar_Df_ex = pd.DataFrame(data = principalComponents_cifar_ex\n",
    "                    , columns = ['principal component 1', 'principal component 2'])\n",
    "principal_cifar_Df_ex['y'] = y_train\n",
    "\n",
    "# SVD Example\n",
    "svd_ex = TruncatedSVD(n_components=ncomp)\n",
    "svd_ex.fit(df_cifar)\n",
    "\n",
    "svd_transform_ex = svd_ex.transform(df_cifar)\n",
    "feat_cols = ['SVD'+str(i + 1) for i in range(svd_transform_ex.shape[1])]\n",
    "svd_cifar_Df_ex = pd.DataFrame(data = svd_transform_ex, columns = feat_cols)\n",
    "svd_cifar_Df_ex['y'] = y_train\n",
    "\n",
    "# NMF Example\n",
    "nmf_ex = NMF(n_components=ncomp)\n",
    "trans_nmf_ex = nmf.fit_transform(df_cifar)\n",
    "\n",
    "feat_cols = ['NMF'+str(i + 1) for i in range(trans_nmf_ex.shape[1])]\n",
    "nmf_cifar_Df_ex = pd.DataFrame(data = trans_nmf_ex, columns = feat_cols)\n",
    "nmf_cifar_Df_ex['y'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,20))\n",
    "\n",
    "# PCA plot\n",
    "plt.subplot(311)\n",
    "plt.gca().set_title('a) Principal Component Analysis')\n",
    "sns.scatterplot(\n",
    "    x=\"principal component 1\", y=\"principal component 2\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=principal_cifar_Df_ex,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "# SVD plot\n",
    "plt.subplot(312)\n",
    "plt.gca().set_title('b) Singular Value Decomposition')\n",
    "sns.scatterplot(\n",
    "    x=\"SVD1\", y=\"SVD2\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=svd_cifar_Df_ex,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "# NMF plot\n",
    "plt.subplot(313)\n",
    "plt.gca().set_title('c) Non-negative Matrix Factorization')\n",
    "sns.scatterplot(\n",
    "    x=\"NMF1\", y=\"NMF2\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=nmf_cifar_Df_ex,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "plt.savefig('images/question1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### 1) Fit the following classifiers on the dataset:\n",
    "    a) Linear SVC\n",
    "    b) Logistic Regresstion Classifier\n",
    "    c) K-nearest Neighbors Classifier\n",
    "    d) Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep testing data\n",
    "x_test = x_test/255.0\n",
    "x_test = x_test.reshape(-1,32,32,3)\n",
    "\n",
    "# reshape image dimensions from three to one\n",
    "x_test_flat = x_test.reshape(-1,3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>...</th>\n",
       "      <th>p91</th>\n",
       "      <th>p92</th>\n",
       "      <th>p93</th>\n",
       "      <th>p94</th>\n",
       "      <th>p95</th>\n",
       "      <th>p96</th>\n",
       "      <th>p97</th>\n",
       "      <th>p98</th>\n",
       "      <th>p99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.479671</td>\n",
       "      <td>0.906426</td>\n",
       "      <td>1.251956</td>\n",
       "      <td>3.164191</td>\n",
       "      <td>-1.918240</td>\n",
       "      <td>1.659476</td>\n",
       "      <td>-0.068083</td>\n",
       "      <td>0.160349</td>\n",
       "      <td>-0.472169</td>\n",
       "      <td>-0.182596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545092</td>\n",
       "      <td>-0.608618</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>-0.183645</td>\n",
       "      <td>0.209230</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>-0.473390</td>\n",
       "      <td>-0.073715</td>\n",
       "      <td>-0.174357</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.943158</td>\n",
       "      <td>-9.580553</td>\n",
       "      <td>5.068578</td>\n",
       "      <td>-2.961200</td>\n",
       "      <td>1.110012</td>\n",
       "      <td>-0.266616</td>\n",
       "      <td>-1.147632</td>\n",
       "      <td>-3.261594</td>\n",
       "      <td>1.486868</td>\n",
       "      <td>-3.944965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413626</td>\n",
       "      <td>0.065850</td>\n",
       "      <td>-0.101268</td>\n",
       "      <td>-0.307669</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>-0.199660</td>\n",
       "      <td>0.099927</td>\n",
       "      <td>-0.676948</td>\n",
       "      <td>0.699004</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.704300</td>\n",
       "      <td>-8.837206</td>\n",
       "      <td>4.109285</td>\n",
       "      <td>1.030721</td>\n",
       "      <td>0.204448</td>\n",
       "      <td>-0.911759</td>\n",
       "      <td>5.313861</td>\n",
       "      <td>1.123139</td>\n",
       "      <td>1.150991</td>\n",
       "      <td>0.448419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031693</td>\n",
       "      <td>-0.224322</td>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-0.280326</td>\n",
       "      <td>-0.046095</td>\n",
       "      <td>-0.143887</td>\n",
       "      <td>0.043336</td>\n",
       "      <td>-0.119398</td>\n",
       "      <td>0.410197</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.046408</td>\n",
       "      <td>-3.812435</td>\n",
       "      <td>6.268061</td>\n",
       "      <td>-0.799734</td>\n",
       "      <td>-0.160306</td>\n",
       "      <td>4.558274</td>\n",
       "      <td>0.988285</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>-1.147928</td>\n",
       "      <td>0.752415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183590</td>\n",
       "      <td>-0.161597</td>\n",
       "      <td>-0.222708</td>\n",
       "      <td>0.778089</td>\n",
       "      <td>0.058857</td>\n",
       "      <td>0.282721</td>\n",
       "      <td>0.413735</td>\n",
       "      <td>-0.300682</td>\n",
       "      <td>-0.444346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.254615</td>\n",
       "      <td>4.320979</td>\n",
       "      <td>1.844344</td>\n",
       "      <td>-0.784487</td>\n",
       "      <td>0.386743</td>\n",
       "      <td>0.410722</td>\n",
       "      <td>0.666861</td>\n",
       "      <td>1.029134</td>\n",
       "      <td>0.203599</td>\n",
       "      <td>0.083327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>0.034242</td>\n",
       "      <td>0.170983</td>\n",
       "      <td>-0.663774</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>-0.183378</td>\n",
       "      <td>-0.217617</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.585919</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1        p2        p3        p4        p5        p6        p7  \\\n",
       "0 -3.479671  0.906426  1.251956  3.164191 -1.918240  1.659476 -0.068083   \n",
       "1  9.943158 -9.580553  5.068578 -2.961200  1.110012 -0.266616 -1.147632   \n",
       "2  4.704300 -8.837206  4.109285  1.030721  0.204448 -0.911759  5.313861   \n",
       "3  8.046408 -3.812435  6.268061 -0.799734 -0.160306  4.558274  0.988285   \n",
       "4 -5.254615  4.320979  1.844344 -0.784487  0.386743  0.410722  0.666861   \n",
       "\n",
       "         p8        p9       p10  ...       p91       p92       p93       p94  \\\n",
       "0  0.160349 -0.472169 -0.182596  ... -0.545092 -0.608618  0.108551 -0.183645   \n",
       "1 -3.261594  1.486868 -3.944965  ...  0.413626  0.065850 -0.101268 -0.307669   \n",
       "2  1.123139  1.150991  0.448419  ... -0.031693 -0.224322 -0.146823 -0.280326   \n",
       "3  0.892768 -1.147928  0.752415  ... -0.183590 -0.161597 -0.222708  0.778089   \n",
       "4  1.029134  0.203599  0.083327  ...  0.187285  0.034242  0.170983 -0.663774   \n",
       "\n",
       "        p95       p96       p97       p98       p99  label  \n",
       "0  0.209230  0.027931 -0.473390 -0.073715 -0.174357      3  \n",
       "1  0.498750 -0.199660  0.099927 -0.676948  0.699004      8  \n",
       "2 -0.046095 -0.143887  0.043336 -0.119398  0.410197      8  \n",
       "3  0.058857  0.282721  0.413735 -0.300682 -0.444346      0  \n",
       "4  0.380714 -0.183378 -0.217617  0.329352  0.585919      6  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform new data using already fitted pca\n",
    "newdata_transformed = pca.transform(x_test_flat)\n",
    "\n",
    "# name each column by pixel number\n",
    "feat_cols = ['p'+str(i + 1) for i in range(newdata_transformed.shape[1])]\n",
    "principal_cifar_test = pd.DataFrame(newdata_transformed,columns=feat_cols)\n",
    "\n",
    "# add image labels\n",
    "principal_cifar_test['label'] = y_test\n",
    "principal_cifar_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = principal_cifar_Df.iloc[:,:-1]\n",
    "X_test = principal_cifar_test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "   \n",
       "        <ul class=\"list-group\">\n",
       "          <li class=\"list-group-item disabled\" aria-disabled=\"true\"><h4>Shape of Train and Test Dataset</h4></li>\n",
       "          <li class=\"list-group-item\"><h4>Number of rows in Train dataset is: <span class=\"label label-primary\">50,000</span></h4></li>\n",
       "          <li class=\"list-group-item\"> <h4>Number of columns Train dataset is <span class=\"label label-primary\">99</span></h4></li>\n",
       "          <li class=\"list-group-item\"><h4>Number of rows in Test dataset is: <span class=\"label label-success\">10,000</span></h4></li>\n",
       "          <li class=\"list-group-item\"><h4>Number of columns Test dataset is <span class=\"label label-success\">99</span></h4></li>\n",
       "        </ul>\n",
       "  \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(f\"\"\"\n",
    "   \n",
    "        <ul class=\"list-group\">\n",
    "          <li class=\"list-group-item disabled\" aria-disabled=\"true\"><h4>Shape of Train and Test Dataset</h4></li>\n",
    "          <li class=\"list-group-item\"><h4>Number of rows in Train dataset is: <span class=\"label label-primary\">{ X_train.shape[0]:,}</span></h4></li>\n",
    "          <li class=\"list-group-item\"> <h4>Number of columns Train dataset is <span class=\"label label-primary\">{X_train.shape[1]}</span></h4></li>\n",
    "          <li class=\"list-group-item\"><h4>Number of rows in Test dataset is: <span class=\"label label-success\">{ X_test.shape[0]:,}</span></h4></li>\n",
    "          <li class=\"list-group-item\"><h4>Number of columns Test dataset is <span class=\"label label-success\">{X_test.shape[1]}</span></h4></li>\n",
    "        </ul>\n",
    "  \n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training labels: (50000,)\n",
      "Shape of the testing labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = principal_cifar_Df.iloc[:,-1]\n",
    "y_test = principal_cifar_test.iloc[:,-1]\n",
    "print('Shape of the training labels: {}'.format(y_train.shape))\n",
    "print('Shape of the testing labels: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = SVC()\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min ± 11.1 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = Model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/y_pred_svc.npy\", y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5395\n",
      "[[616  28  56  19  27  22  19  25 143  45]\n",
      " [ 33 653  18  43   7  22  15  25  55 129]\n",
      " [ 82  28 398  96 135  56 118  47  27  13]\n",
      " [ 32  23  80 384  61 170 120  44  30  56]\n",
      " [ 46  13 154  69 429  39 139  69  24  18]\n",
      " [ 22  14  82 197  69 435  83  54  20  24]\n",
      " [ 10  17  74  91 100  39 630  14  11  14]\n",
      " [ 39  20  55  66  79  71  37 559  15  59]\n",
      " [ 87  61  18  29  23  18  13  15 683  53]\n",
      " [ 44 143  11  46  11  15  24  35  63 608]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.61      1000\n",
      "           1       0.65      0.65      0.65      1000\n",
      "           2       0.42      0.40      0.41      1000\n",
      "           3       0.37      0.38      0.38      1000\n",
      "           4       0.46      0.43      0.44      1000\n",
      "           5       0.49      0.43      0.46      1000\n",
      "           6       0.53      0.63      0.57      1000\n",
      "           7       0.63      0.56      0.59      1000\n",
      "           8       0.64      0.68      0.66      1000\n",
      "           9       0.60      0.61      0.60      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.54      0.54      0.54     10000\n",
      "weighted avg       0.54      0.54      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load prediction array\n",
    "np.load(\"results/y_pred_svc.npy\")\n",
    "\n",
    "# Accuracy score\n",
    "print('Accuracy : ',accuracy_score(y_pred_svc,y_test))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "parta = classification_report(y_test, y_pred_svc)\n",
    "print(parta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Logistic Regresstion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=400)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = LogisticRegression(max_iter = 400)\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84 s ± 52.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "Model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/y_pred_log.npy\", y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.3955\n",
      "[[457  55  60  29  18  35  25  55 194  72]\n",
      " [ 64 494  30  34  24  41  39  49  80 145]\n",
      " [102  43 256  88 127  87 159  68  46  24]\n",
      " [ 42  66  98 270  59 176 135  53  38  63]\n",
      " [ 54  30 150  63 285  79 169 117  29  24]\n",
      " [ 49  50  96 157  71 325  96  80  53  23]\n",
      " [ 10  41  78 132  97  73 484  32  17  36]\n",
      " [ 45  37  68  57  96  71  70 422  46  88]\n",
      " [155  67  21  29  12  49  13  18 524 112]\n",
      " [ 73 181  25  33  13  23  47  56 111 438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.46      0.45      1000\n",
      "           1       0.46      0.49      0.48      1000\n",
      "           2       0.29      0.26      0.27      1000\n",
      "           3       0.30      0.27      0.29      1000\n",
      "           4       0.36      0.28      0.32      1000\n",
      "           5       0.34      0.33      0.33      1000\n",
      "           6       0.39      0.48      0.43      1000\n",
      "           7       0.44      0.42      0.43      1000\n",
      "           8       0.46      0.52      0.49      1000\n",
      "           9       0.43      0.44      0.43      1000\n",
      "\n",
      "    accuracy                           0.40     10000\n",
      "   macro avg       0.39      0.40      0.39     10000\n",
      "weighted avg       0.39      0.40      0.39     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load prediction array\n",
    "np.load(\"results/y_pred_log.npy\")\n",
    "\n",
    "# Accuracy score\n",
    "print('Accuracy : ',accuracy_score(y_pred_log,y_test))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "partb = classification_report(y_test, y_pred_log)\n",
    "print(partb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) K-nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = KNeighborsClassifier(n_neighbors=10)\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 ms ± 15.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "Model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/y_pred_knn.npy\", y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.3824\n",
      "[[563  12 100  14  49   7  33  14 204   4]\n",
      " [ 99 276  92  34 121  21 106  19 197  35]\n",
      " [109   4 429  39 222  24 114  16  40   3]\n",
      " [ 56  13 202 184 181  90 192  24  43  15]\n",
      " [ 61   2 252  26 507   7  82  24  39   0]\n",
      " [ 47   8 194 129 188 229 130  19  49   7]\n",
      " [ 18   0 210  29 247  18 453   4  18   3]\n",
      " [ 81   9 146  47 252  53  82 263  52  15]\n",
      " [126  14  40  31  59   9  25   9 674  13]\n",
      " [140  77  59  32 102  19  91  25 209 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.49      1000\n",
      "           1       0.67      0.28      0.39      1000\n",
      "           2       0.25      0.43      0.31      1000\n",
      "           3       0.33      0.18      0.24      1000\n",
      "           4       0.26      0.51      0.35      1000\n",
      "           5       0.48      0.23      0.31      1000\n",
      "           6       0.35      0.45      0.39      1000\n",
      "           7       0.63      0.26      0.37      1000\n",
      "           8       0.44      0.67      0.53      1000\n",
      "           9       0.72      0.25      0.37      1000\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.46      0.38      0.38     10000\n",
      "weighted avg       0.46      0.38      0.38     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load prediction array\n",
    "np.load(\"results/y_pred_knn.npy\")\n",
    "\n",
    "# Accuracy score\n",
    "print('Accuracy : ',accuracy_score(y_pred_knn,y_test))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "partc = classification_report(y_test, y_pred_knn)\n",
    "print(partc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(random_state=1021)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = Perceptron(tol=1e-3, random_state=1021)\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 14.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/y_pred_p.npy\", y_pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.2262\n",
      "[[218 104  28  95  37  27   9  43 131 308]\n",
      " [ 44 353  45  48  12  81  22  41 193 161]\n",
      " [ 47  66 188 136  99 156  71  63  78  96]\n",
      " [ 30  93 147 144  32 195  52  89 120  98]\n",
      " [ 43  70 228  56 147 163  69 104  56  64]\n",
      " [ 33  83 123 129  65 198  41 120 110  98]\n",
      " [ 12  47 180  71  60 256 147  78  79  70]\n",
      " [ 62  79 108  68  70 121  27 237  92 136]\n",
      " [113 117  17 109  12  23  10  20 315 264]\n",
      " [ 87 178  40  52  17  67  27  37 180 315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.22      0.26      1000\n",
      "           1       0.30      0.35      0.32      1000\n",
      "           2       0.17      0.19      0.18      1000\n",
      "           3       0.16      0.14      0.15      1000\n",
      "           4       0.27      0.15      0.19      1000\n",
      "           5       0.15      0.20      0.17      1000\n",
      "           6       0.31      0.15      0.20      1000\n",
      "           7       0.28      0.24      0.26      1000\n",
      "           8       0.23      0.32      0.27      1000\n",
      "           9       0.20      0.32      0.24      1000\n",
      "\n",
      "    accuracy                           0.23     10000\n",
      "   macro avg       0.24      0.23      0.22     10000\n",
      "weighted avg       0.24      0.23      0.22     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load prediction array\n",
    "np.load(\"results/y_pred_p.npy\")\n",
    "\n",
    "# Accuracy score\n",
    "print('Accuracy : ',accuracy_score(y_pred_p,y_test))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_p))\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "partd = classification_report(y_test, y_pred_p)\n",
    "print(partd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Report various metrics of the test data for the fitted models, such as averaged \n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "- accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "svc_pre = precision_score(y_pred_svc,y_test, average = \"macro\")\n",
    "log_pre = precision_score(y_pred_log,y_test, average = \"macro\")\n",
    "knn_pre = precision_score(y_pred_knn,y_test, average = \"macro\")\n",
    "p_pre = precision_score(y_pred_p,y_test, average = \"macro\")\n",
    "\n",
    "# recall \n",
    "svc_recall = round(recall_score(y_pred_svc,y_test, average = \"macro\"),4)\n",
    "log_recall = round(recall_score(y_pred_log,y_test, average = \"macro\"),4)\n",
    "knn_recall = round(recall_score(y_pred_knn,y_test, average = \"macro\"),4)\n",
    "p_recall = round(recall_score(y_pred_p,y_test, average = \"macro\"),4)\n",
    "\n",
    "# f1 score\n",
    "svc_f1 = round(f1_score(y_pred_svc,y_test, average = \"macro\"),4)\n",
    "log_f1 = round(f1_score(y_pred_log,y_test, average = \"macro\"),4)\n",
    "knn_f1 = round(f1_score(y_pred_knn,y_test, average = \"macro\"),4)\n",
    "p_f1 = round(f1_score(y_pred_p,y_test, average = \"macro\"),4)\n",
    "\n",
    "# accuracy\n",
    "svc_acc = accuracy_score(y_pred_svc,y_test)\n",
    "log_acc = accuracy_score(y_pred_log,y_test)\n",
    "knn_acc = accuracy_score(y_pred_knn,y_test)\n",
    "p_acc = accuracy_score(y_pred_p,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Classifier':['Linear SVC', 'Logistic Regression Classifier', 'K-nearest Neighbors Classifier', 'Perceptron'],\n",
    "        'Precision':[svc_pre, log_pre, knn_pre, p_pre],\n",
    "        'Recall':[svc_recall, log_recall, knn_recall, p_recall],\n",
    "        'F1 Score':[svc_f1, log_f1, knn_f1, p_f1],\n",
    "        'Accuracy':[svc_acc, log_acc, knn_acc, p_acc]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.5389</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.5395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.3910</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-nearest Neighbors Classifier</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Classifier  Precision  Recall  F1 Score  Accuracy\n",
       "0                      Linear SVC     0.5395  0.5389    0.5382    0.5395\n",
       "1  Logistic Regression Classifier     0.3955  0.3910    0.3918    0.3955\n",
       "2  K-nearest Neighbors Classifier     0.3824  0.4556    0.3751    0.3824\n",
       "3                      Perceptron     0.2262  0.2385    0.2240    0.2262"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary into DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "#### 1)\tThere are several combinations of dimensionality reduction methods, model selection and hyperparameter values for both. Use sklearn’s GridSearchCV and Pipeline features to go over these combinations for selecting the combination that gives the best f1 score averaged over 5 folds (5-cross validation). Each model in grid search takes a relatively large amount of time to train. Specifically, you need to consider the following options:\n",
    "    a)\tDimensionality reduction method (2 options)\n",
    "    b)\tClassification model used (4 options)\n",
    "    c)\tFor models that support only binary classification, 1-vs-1 or 1-vs-rest? (2 options)\n",
    "    d)\tType of regularization (if applicable) (l1, l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = {'n_neighbors': np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=3) # GridSearchCV\n",
    "knn_cv.fit(X,y) # Fit\n",
    "\n",
    "# Print hyperparameter\n",
    "print(\"Tuned hyperparameter k: {}\".format(knn_cv.best_params_)) \n",
    "print(\"Best score: {}\".format(knn_cv.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)\tRun the grid search and describe the best pipeline you found. Report various metrics for this pipeline, such as averaged precision, recall, f1 score and accuracy on the test data. Why are they so low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
